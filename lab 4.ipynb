{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83f26a29",
   "metadata": {
    "id": "83f26a29"
   },
   "source": [
    "# Unsupervised Lab Session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea571d1",
   "metadata": {
    "id": "8ea571d1"
   },
   "source": [
    "## Learning outcomes:\n",
    "- Exploratory data analysis and data preparation for model building.\n",
    "- PCA for dimensionality reduction.\n",
    "- K-means and Agglomerative Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f778a",
   "metadata": {
    "id": "fd7f778a"
   },
   "source": [
    "## Problem Statement\n",
    "Based on the given marketing campigan dataset, segment the similar customers into suitable clusters. Analyze the clusters and provide your insights to help the organization promote their business."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b58f8f",
   "metadata": {
    "id": "33b58f8f"
   },
   "source": [
    "## Context:\n",
    "- Customer Personality Analysis is a detailed analysis of a company’s ideal customers. It helps a business to better understand its customers and makes it easier for them to modify products according to the specific needs, behaviors and concerns of different types of customers.\n",
    "- Customer personality analysis helps a business to modify its product based on its target customers from different types of customer segments. For example, instead of spending money to market a new product to every customer in the company’s database, a company can analyze which customer segment is most likely to buy the product and then market the product only on that particular segment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867166aa",
   "metadata": {
    "id": "867166aa"
   },
   "source": [
    "## About dataset\n",
    "- Source: https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis?datasetId=1546318&sortBy=voteCount\n",
    "\n",
    "### Attribute Information:\n",
    "- ID: Customer's unique identifier\n",
    "- Year_Birth: Customer's birth year\n",
    "- Education: Customer's education level\n",
    "- Marital_Status: Customer's marital status\n",
    "- Income: Customer's yearly household income\n",
    "- Kidhome: Number of children in customer's household\n",
    "- Teenhome: Number of teenagers in customer's household\n",
    "- Dt_Customer: Date of customer's enrollment with the company\n",
    "- Recency: Number of days since customer's last purchase\n",
    "- Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n",
    "- MntWines: Amount spent on wine in last 2 years\n",
    "- MntFruits: Amount spent on fruits in last 2 years\n",
    "- MntMeatProducts: Amount spent on meat in last 2 years\n",
    "- MntFishProducts: Amount spent on fish in last 2 years\n",
    "- MntSweetProducts: Amount spent on sweets in last 2 years\n",
    "- MntGoldProds: Amount spent on gold in last 2 years\n",
    "- NumDealsPurchases: Number of purchases made with a discount\n",
    "- AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
    "- AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
    "- AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
    "- AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
    "- AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
    "- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "- NumWebPurchases: Number of purchases made through the company’s website\n",
    "- NumCatalogPurchases: Number of purchases made using a catalogue\n",
    "- NumStorePurchases: Number of purchases made directly in stores\n",
    "- NumWebVisitsMonth: Number of visits to company’s website in the last month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a830406",
   "metadata": {
    "id": "5a830406"
   },
   "source": [
    "### 1. Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d65c5528",
   "metadata": {
    "id": "d65c5528"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,roc_curve,accuracy_score,auc,roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80eb960",
   "metadata": {
    "id": "c80eb960"
   },
   "source": [
    "### 2. Load the CSV file (i.e marketing.csv) and display the first 5 rows of the dataframe. Check the shape and info of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1caebc10",
   "metadata": {
    "id": "1caebc10"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
      "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
      "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
      "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
      "4  5324        1981         PhD        Married  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
      "0    4/9/2012       58       635  ...                   10                  4   \n",
      "1    8/3/2014       38        11  ...                    1                  2   \n",
      "2  21-08-2013       26       426  ...                    2                 10   \n",
      "3   10/2/2014       26        11  ...                    0                  4   \n",
      "4  19-01-2014       94       173  ...                    3                  6   \n",
      "\n",
      "   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
      "0                  7             0             0             0             0   \n",
      "1                  5             0             0             0             0   \n",
      "2                  4             0             0             0             0   \n",
      "3                  6             0             0             0             0   \n",
      "4                  5             0             0             0             0   \n",
      "\n",
      "   AcceptedCmp2  Complain  Response  \n",
      "0             0         0         1  \n",
      "1             0         0         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         0         0  \n",
      "\n",
      "[5 rows x 27 columns]\n",
      "Shape of the dataset: (2240, 27)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 27 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   2240 non-null   int64  \n",
      " 1   Year_Birth           2240 non-null   int64  \n",
      " 2   Education            2240 non-null   object \n",
      " 3   Marital_Status       2240 non-null   object \n",
      " 4   Income               2216 non-null   float64\n",
      " 5   Kidhome              2240 non-null   int64  \n",
      " 6   Teenhome             2240 non-null   int64  \n",
      " 7   Dt_Customer          2240 non-null   object \n",
      " 8   Recency              2240 non-null   int64  \n",
      " 9   MntWines             2240 non-null   int64  \n",
      " 10  MntFruits            2240 non-null   int64  \n",
      " 11  MntMeatProducts      2240 non-null   int64  \n",
      " 12  MntFishProducts      2240 non-null   int64  \n",
      " 13  MntSweetProducts     2240 non-null   int64  \n",
      " 14  MntGoldProds         2240 non-null   int64  \n",
      " 15  NumDealsPurchases    2240 non-null   int64  \n",
      " 16  NumWebPurchases      2240 non-null   int64  \n",
      " 17  NumCatalogPurchases  2240 non-null   int64  \n",
      " 18  NumStorePurchases    2240 non-null   int64  \n",
      " 19  NumWebVisitsMonth    2240 non-null   int64  \n",
      " 20  AcceptedCmp3         2240 non-null   int64  \n",
      " 21  AcceptedCmp4         2240 non-null   int64  \n",
      " 22  AcceptedCmp5         2240 non-null   int64  \n",
      " 23  AcceptedCmp1         2240 non-null   int64  \n",
      " 24  AcceptedCmp2         2240 non-null   int64  \n",
      " 25  Complain             2240 non-null   int64  \n",
      " 26  Response             2240 non-null   int64  \n",
      "dtypes: float64(1), int64(23), object(3)\n",
      "memory usage: 472.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('marketing.csv')\n",
    "print(df.head(5))\n",
    "print(\"Shape of the dataset:\", df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef75724",
   "metadata": {
    "id": "9ef75724"
   },
   "source": [
    "### 3. Check the percentage of missing values? If there is presence of missing values, treat them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08616f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of missing values:\n",
      "ID                     0.00\n",
      "Year_Birth             0.00\n",
      "Education              0.00\n",
      "Marital_Status         0.00\n",
      "Income                 1.07\n",
      "Kidhome                0.00\n",
      "Teenhome               0.00\n",
      "Dt_Customer            0.00\n",
      "Recency                0.00\n",
      "MntWines               0.00\n",
      "MntFruits              0.00\n",
      "MntMeatProducts        0.00\n",
      "MntFishProducts        0.00\n",
      "MntSweetProducts       0.00\n",
      "MntGoldProds           0.00\n",
      "NumDealsPurchases      0.00\n",
      "NumWebPurchases        0.00\n",
      "NumCatalogPurchases    0.00\n",
      "NumStorePurchases      0.00\n",
      "NumWebVisitsMonth      0.00\n",
      "AcceptedCmp3           0.00\n",
      "AcceptedCmp4           0.00\n",
      "AcceptedCmp5           0.00\n",
      "AcceptedCmp1           0.00\n",
      "AcceptedCmp2           0.00\n",
      "Complain               0.00\n",
      "Response               0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('marketing.csv')\n",
    "missing_percentage = (df.isna().mean() * 100).round(2)\n",
    "print(\"Percentage of missing values:\")\n",
    "print(missing_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c2b1a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
      "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
      "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
      "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
      "4  5324        1981         PhD        Married  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
      "0    4/9/2012       58       635  ...                   10                  4   \n",
      "1    8/3/2014       38        11  ...                    1                  2   \n",
      "2  21-08-2013       26       426  ...                    2                 10   \n",
      "3   10/2/2014       26        11  ...                    0                  4   \n",
      "4  19-01-2014       94       173  ...                    3                  6   \n",
      "\n",
      "   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
      "0                  7             0             0             0             0   \n",
      "1                  5             0             0             0             0   \n",
      "2                  4             0             0             0             0   \n",
      "3                  6             0             0             0             0   \n",
      "4                  5             0             0             0             0   \n",
      "\n",
      "   AcceptedCmp2  Complain  Response  \n",
      "0             0         0         1  \n",
      "1             0         0         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         0         0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('marketing.csv')\n",
    "df_filled = df.fillna(df.mean())\n",
    "print(df_filled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3709e",
   "metadata": {
    "id": "86f3709e"
   },
   "source": [
    "### 4. Check if there are any duplicate records in the dataset? If any drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2c231df",
   "metadata": {
    "id": "f2c231df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicate records found.\n",
      "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
      "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
      "2  4141        1965  Graduation       Together  71613.0        0         0   \n",
      "3  6182        1984  Graduation       Together  26646.0        1         0   \n",
      "4  5324        1981         PhD        Married  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumCatalogPurchases  NumStorePurchases  \\\n",
      "0    4/9/2012       58       635  ...                   10                  4   \n",
      "1    8/3/2014       38        11  ...                    1                  2   \n",
      "2  21-08-2013       26       426  ...                    2                 10   \n",
      "3   10/2/2014       26        11  ...                    0                  4   \n",
      "4  19-01-2014       94       173  ...                    3                  6   \n",
      "\n",
      "   NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  \\\n",
      "0                  7             0             0             0             0   \n",
      "1                  5             0             0             0             0   \n",
      "2                  4             0             0             0             0   \n",
      "3                  6             0             0             0             0   \n",
      "4                  5             0             0             0             0   \n",
      "\n",
      "   AcceptedCmp2  Complain  Response  \n",
      "0             0         0         1  \n",
      "1             0         0         0  \n",
      "2             0         0         0  \n",
      "3             0         0         0  \n",
      "4             0         0         0  \n",
      "\n",
      "[5 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_records = df.duplicated()\n",
    "num_duplicates = duplicate_records.sum()\n",
    "if num_duplicates > 0:\n",
    "   \n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    print(f\"{num_duplicates} duplicate record(s) found and dropped.\")\n",
    "else:\n",
    "    print(\"No duplicate records found.\")\n",
    "\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6f2b5a",
   "metadata": {
    "id": "3a6f2b5a"
   },
   "source": [
    "### 5. Drop the columns which you think redundant for the analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9ca818b",
   "metadata": {
    "id": "a9ca818b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  Recency  \\\n",
      "0        1957  Graduation         Single  58138.0        0         0       58   \n",
      "1        1954  Graduation         Single  46344.0        1         1       38   \n",
      "2        1965  Graduation       Together  71613.0        0         0       26   \n",
      "3        1984  Graduation       Together  26646.0        1         0       26   \n",
      "4        1981         PhD        Married  58293.0        1         0       94   \n",
      "\n",
      "   MntWines  MntFruits  MntMeatProducts  ...  NumCatalogPurchases  \\\n",
      "0       635         88              546  ...                   10   \n",
      "1        11          1                6  ...                    1   \n",
      "2       426         49              127  ...                    2   \n",
      "3        11          4               20  ...                    0   \n",
      "4       173         43              118  ...                    3   \n",
      "\n",
      "   NumStorePurchases  NumWebVisitsMonth  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0                  4                  7             0             0   \n",
      "1                  2                  5             0             0   \n",
      "2                 10                  4             0             0   \n",
      "3                  4                  6             0             0   \n",
      "4                  6                  5             0             0   \n",
      "\n",
      "   AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \n",
      "0             0             0             0         0         1  \n",
      "1             0             0             0         0         0  \n",
      "2             0             0             0         0         0  \n",
      "3             0             0             0         0         0  \n",
      "4             0             0             0         0         0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "redundant_columns = ['ID', 'Dt_Customer']\n",
    "df_dropped = df.drop(redundant_columns, axis=1)\n",
    "print(df_dropped.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff0a112",
   "metadata": {
    "id": "4ff0a112"
   },
   "source": [
    "### 6. Check the unique categories in the column 'Marital_Status'\n",
    "- i) Group categories 'Married', 'Together' as 'relationship'\n",
    "- ii) Group categories 'Divorced', 'Widow', 'Alone', 'YOLO', and 'Absurd' as 'Single'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb1be519",
   "metadata": {
    "id": "eb1be519"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Categories in 'Marital_Status':\n",
      "['Single' 'Together' 'Married' 'Divorced' 'Widow' 'Alone' 'Absurd' 'YOLO']\n",
      "\n",
      "Unique Categories in 'Marital_Status' after Grouping:\n",
      "['Single' 'relationship']\n"
     ]
    }
   ],
   "source": [
    "unique_categories = df['Marital_Status'].unique()\n",
    "print(\"Unique Categories in 'Marital_Status':\")\n",
    "print(unique_categories)\n",
    "df['Marital_Status'] = df['Marital_Status'].replace(['Married', 'Together'], 'relationship')\n",
    "df['Marital_Status'] = df['Marital_Status'].replace(['Divorced', 'Widow', 'Alone', 'YOLO', 'Absurd'], 'Single')\n",
    "unique_categories_updated = df['Marital_Status'].unique()\n",
    "print(\"\\nUnique Categories in 'Marital_Status' after Grouping:\")\n",
    "print(unique_categories_updated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9566bfbe",
   "metadata": {
    "id": "9566bfbe"
   },
   "source": [
    "### 7. Group the columns 'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', and 'MntGoldProds' as 'Total_Expenses'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3fa800",
   "metadata": {
    "id": "3c3fa800"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
      "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
      "2  4141        1965  Graduation   relationship  71613.0        0         0   \n",
      "3  6182        1984  Graduation   relationship  26646.0        1         0   \n",
      "4  5324        1981         PhD   relationship  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumStorePurchases  NumWebVisitsMonth  \\\n",
      "0    4/9/2012       58       635  ...                  4                  7   \n",
      "1    8/3/2014       38        11  ...                  2                  5   \n",
      "2  21-08-2013       26       426  ...                 10                  4   \n",
      "3   10/2/2014       26        11  ...                  4                  6   \n",
      "4  19-01-2014       94       173  ...                  6                  5   \n",
      "\n",
      "   AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             0             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             0             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   Complain  Response  Total_Expenses  \n",
      "0         0         1            1617  \n",
      "1         0         0              27  \n",
      "2         0         0             776  \n",
      "3         0         0              53  \n",
      "4         0         0             422  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Total_Expenses'] = df[['MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "                           'MntSweetProducts', 'MntGoldProds']].sum(axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0cd083",
   "metadata": {
    "id": "bf0cd083"
   },
   "source": [
    "### 8. Group the columns 'NumWebPurchases', 'NumCatalogPurchases', 'NumStorePurchases', and 'NumDealsPurchases' as 'Num_Total_Purchases'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c535ede",
   "metadata": {
    "id": "9c535ede"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957  Graduation         Single  58138.0        0         0   \n",
      "1  2174        1954  Graduation         Single  46344.0        1         1   \n",
      "2  4141        1965  Graduation   relationship  71613.0        0         0   \n",
      "3  6182        1984  Graduation   relationship  26646.0        1         0   \n",
      "4  5324        1981         PhD   relationship  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  AcceptedCmp3  \\\n",
      "0    4/9/2012       58       635  ...                  7             0   \n",
      "1    8/3/2014       38        11  ...                  5             0   \n",
      "2  21-08-2013       26       426  ...                  4             0   \n",
      "3   10/2/2014       26        11  ...                  6             0   \n",
      "4  19-01-2014       94       173  ...                  5             0   \n",
      "\n",
      "   AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \\\n",
      "0             0             0             0             0         0         1   \n",
      "1             0             0             0             0         0         0   \n",
      "2             0             0             0             0         0         0   \n",
      "3             0             0             0             0         0         0   \n",
      "4             0             0             0             0         0         0   \n",
      "\n",
      "   Total_Expenses  Num_Total_Purchases  \n",
      "0            1617                   25  \n",
      "1              27                    6  \n",
      "2             776                   21  \n",
      "3              53                    8  \n",
      "4             422                   19  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Num_Total_Purchases'] = df[['NumWebPurchases', 'NumCatalogPurchases', \n",
    "                                'NumStorePurchases', 'NumDealsPurchases']].sum(axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d2dca5",
   "metadata": {
    "id": "52d2dca5"
   },
   "source": [
    "### 9. Group the columns 'Kidhome' and 'Teenhome' as 'Kids'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7c861a1",
   "metadata": {
    "id": "f7c861a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income Dt_Customer  Recency  \\\n",
      "0  5524        1957  Graduation         Single  58138.0    4/9/2012       58   \n",
      "1  2174        1954  Graduation         Single  46344.0    8/3/2014       38   \n",
      "2  4141        1965  Graduation   relationship  71613.0  21-08-2013       26   \n",
      "3  6182        1984  Graduation   relationship  26646.0   10/2/2014       26   \n",
      "4  5324        1981         PhD   relationship  58293.0  19-01-2014       94   \n",
      "\n",
      "   MntWines  MntFruits  MntMeatProducts  ...  AcceptedCmp3  AcceptedCmp4  \\\n",
      "0       635         88              546  ...             0             0   \n",
      "1        11          1                6  ...             0             0   \n",
      "2       426         49              127  ...             0             0   \n",
      "3        11          4               20  ...             0             0   \n",
      "4       173         43              118  ...             0             0   \n",
      "\n",
      "   AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  Complain  Response  \\\n",
      "0             0             0             0         0         1   \n",
      "1             0             0             0         0         0   \n",
      "2             0             0             0         0         0   \n",
      "3             0             0             0         0         0   \n",
      "4             0             0             0         0         0   \n",
      "\n",
      "   Total_Expenses  Num_Total_Purchases  Kids  \n",
      "0            1617                   25     0  \n",
      "1              27                    6     2  \n",
      "2             776                   21     0  \n",
      "3              53                    8     1  \n",
      "4             422                   19     1  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "df['Kids'] = df[['Kidhome', 'Teenhome']].sum(axis=1)\n",
    "df = df.drop(['Kidhome', 'Teenhome'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f67474",
   "metadata": {
    "id": "36f67474"
   },
   "source": [
    "### 10. Group columns 'AcceptedCmp1 , 2 , 3 , 4, 5' and 'Response' as 'TotalAcceptedCmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecc9109f",
   "metadata": {
    "id": "ecc9109f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth   Education Marital_Status   Income Dt_Customer  Recency  \\\n",
      "0  5524        1957  Graduation         Single  58138.0    4/9/2012       58   \n",
      "1  2174        1954  Graduation         Single  46344.0    8/3/2014       38   \n",
      "2  4141        1965  Graduation   relationship  71613.0  21-08-2013       26   \n",
      "3  6182        1984  Graduation   relationship  26646.0   10/2/2014       26   \n",
      "4  5324        1981         PhD   relationship  58293.0  19-01-2014       94   \n",
      "\n",
      "   MntWines  MntFruits  MntMeatProducts  ...  NumDealsPurchases  \\\n",
      "0       635         88              546  ...                  3   \n",
      "1        11          1                6  ...                  2   \n",
      "2       426         49              127  ...                  1   \n",
      "3        11          4               20  ...                  2   \n",
      "4       173         43              118  ...                  5   \n",
      "\n",
      "   NumWebPurchases  NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  \\\n",
      "0                8                   10                  4                  7   \n",
      "1                1                    1                  2                  5   \n",
      "2                8                    2                 10                  4   \n",
      "3                2                    0                  4                  6   \n",
      "4                5                    3                  6                  5   \n",
      "\n",
      "   Complain  Total_Expenses  Num_Total_Purchases  Kids  TotalAcceptedCmp  \n",
      "0         0            1617                   25     0                 1  \n",
      "1         0              27                    6     2                 0  \n",
      "2         0             776                   21     0                 0  \n",
      "3         0              53                    8     1                 0  \n",
      "4         0             422                   19     1                 0  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "df['TotalAcceptedCmp'] = df[['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3',\n",
    "                             'AcceptedCmp4', 'AcceptedCmp5', 'Response']].sum(axis=1)\n",
    "df = df.drop(['AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3',\n",
    "              'AcceptedCmp4', 'AcceptedCmp5', 'Response'], axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886bfb08",
   "metadata": {
    "id": "886bfb08"
   },
   "source": [
    "### 11. Drop those columns which we have used above for obtaining new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60ee971",
   "metadata": {},
   "outputs": [],
   "source": [
    "already dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225ced7",
   "metadata": {
    "id": "4225ced7"
   },
   "source": [
    "### 12. Extract 'age' using the column 'Year_Birth' and then drop the column 'Year_birth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d517611e",
   "metadata": {
    "id": "d517611e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID   Education Marital_Status   Income Dt_Customer  Recency  MntWines  \\\n",
      "0  5524  Graduation         Single  58138.0    4/9/2012       58       635   \n",
      "1  2174  Graduation         Single  46344.0    8/3/2014       38        11   \n",
      "2  4141  Graduation   relationship  71613.0  21-08-2013       26       426   \n",
      "3  6182  Graduation   relationship  26646.0   10/2/2014       26        11   \n",
      "4  5324         PhD   relationship  58293.0  19-01-2014       94       173   \n",
      "\n",
      "   MntFruits  MntMeatProducts  MntFishProducts  ...  NumWebPurchases  \\\n",
      "0         88              546              172  ...                8   \n",
      "1          1                6                2  ...                1   \n",
      "2         49              127              111  ...                8   \n",
      "3          4               20               10  ...                2   \n",
      "4         43              118               46  ...                5   \n",
      "\n",
      "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  Complain  \\\n",
      "0                   10                  4                  7         0   \n",
      "1                    1                  2                  5         0   \n",
      "2                    2                 10                  4         0   \n",
      "3                    0                  4                  6         0   \n",
      "4                    3                  6                  5         0   \n",
      "\n",
      "   Total_Expenses  Num_Total_Purchases  Kids  TotalAcceptedCmp  Age  \n",
      "0            1617                   25     0                 1   66  \n",
      "1              27                    6     2                 0   69  \n",
      "2             776                   21     0                 0   58  \n",
      "3              53                    8     1                 0   39  \n",
      "4             422                   19     1                 0   42  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "current_year = pd.to_datetime('today').year\n",
    "df['Age'] = current_year - df['Year_Birth']\n",
    "df = df.drop('Year_Birth', axis=1)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d3c92d",
   "metadata": {
    "id": "f2d3c92d"
   },
   "source": [
    "### 13. Encode the categorical variables in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "030cfc32",
   "metadata": {
    "id": "030cfc32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID  Year_Birth  Education  Marital_Status   Income  Kidhome  Teenhome  \\\n",
      "0  5524        1957          2               4  58138.0        0         0   \n",
      "1  2174        1954          2               4  46344.0        1         1   \n",
      "2  4141        1965          2               5  71613.0        0         0   \n",
      "3  6182        1984          2               5  26646.0        1         0   \n",
      "4  5324        1981          4               3  58293.0        1         0   \n",
      "\n",
      "  Dt_Customer  Recency  MntWines  ...  NumStorePurchases  NumWebVisitsMonth  \\\n",
      "0    4/9/2012       58       635  ...                  4                  7   \n",
      "1    8/3/2014       38        11  ...                  2                  5   \n",
      "2  21-08-2013       26       426  ...                 10                  4   \n",
      "3   10/2/2014       26        11  ...                  4                  6   \n",
      "4  19-01-2014       94       173  ...                  6                  5   \n",
      "\n",
      "   AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  \\\n",
      "0             0             0             0             0             0   \n",
      "1             0             0             0             0             0   \n",
      "2             0             0             0             0             0   \n",
      "3             0             0             0             0             0   \n",
      "4             0             0             0             0             0   \n",
      "\n",
      "   Complain  Response  Cluster  \n",
      "0         0         1        0  \n",
      "1         0         0        1  \n",
      "2         0         0        0  \n",
      "3         0         0        1  \n",
      "4         0         0        0  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['Education'] = label_encoder.fit_transform(df['Education'])\n",
    "df['Marital_Status'] = label_encoder.fit_transform(df['Marital_Status'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9242e36d",
   "metadata": {
    "id": "9242e36d"
   },
   "source": [
    "### 14. Standardize the columns, so that values are in a particular range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72475b68",
   "metadata": {
    "id": "72475b68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID   Education Marital_Status    Income Dt_Customer  Recency  MntWines  \\\n",
      "0  5524  Graduation         Single  0.234063    4/9/2012       58       635   \n",
      "1  2174  Graduation         Single -0.234559    8/3/2014       38        11   \n",
      "2  4141  Graduation   relationship  0.769478  21-08-2013       26       426   \n",
      "3  6182  Graduation   relationship -1.017239   10/2/2014       26        11   \n",
      "4  5324         PhD   relationship  0.240221  19-01-2014       94       173   \n",
      "\n",
      "   MntFruits  MntMeatProducts  MntFishProducts  ...  NumWebPurchases  \\\n",
      "0         88              546              172  ...                8   \n",
      "1          1                6                2  ...                1   \n",
      "2         49              127              111  ...                8   \n",
      "3          4               20               10  ...                2   \n",
      "4         43              118               46  ...                5   \n",
      "\n",
      "   NumCatalogPurchases  NumStorePurchases  NumWebVisitsMonth  Complain  \\\n",
      "0                   10                  4                  7         0   \n",
      "1                    1                  2                  5         0   \n",
      "2                    2                 10                  4         0   \n",
      "3                    0                  4                  6         0   \n",
      "4                    3                  6                  5         0   \n",
      "\n",
      "   Total_Expenses  Num_Total_Purchases  Kids  TotalAcceptedCmp  Age  \n",
      "0        1.679417             1.320826     0                 1   66  \n",
      "1       -0.961275            -1.154596     2                 0   69  \n",
      "2        0.282673             0.799685     0                 0   58  \n",
      "3       -0.918094            -0.894025     1                 0   39  \n",
      "4       -0.305254             0.539114     1                 0   42  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_to_standardize = ['Income', 'Total_Expenses', 'Num_Total_Purchases']\n",
    "scaler = StandardScaler()\n",
    "df[columns_to_standardize] = scaler.fit_transform(df[columns_to_standardize])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d063d2e2",
   "metadata": {
    "id": "d063d2e2"
   },
   "source": [
    "### 15. Apply PCA on the above dataset and determine the number of PCA components to be used so that 90-95% of the variance in data is explained by the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6df3c70e",
   "metadata": {
    "id": "6df3c70e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components for 90% explained variance: 8\n",
      "Explained variance with 8 components: 0.9072081565519596\n",
      "Number of components for 95% explained variance: 10\n",
      "Explained variance with 10 components: 0.9733824180692581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "columns_for_pca = ['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
    "                          'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "                          'NumWebVisitsMonth']\n",
    "df = df.dropna(subset=columns_for_pca)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=columns_for_pca)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[columns_for_pca])\n",
    "pca = PCA()\n",
    "pca.fit(df_scaled)\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "n_components_90 = np.argmax(cumulative_variance >= 0.9) + 1\n",
    "n_components_95 = np.argmax(cumulative_variance >= 0.95) + 1\n",
    "print(f\"Number of components for 90% explained variance: {n_components_90}\")\n",
    "print(f\"Explained variance with {n_components_90} components: {cumulative_variance[n_components_90-1]}\")\n",
    "print(f\"Number of components for 95% explained variance: {n_components_95}\")\n",
    "print(f\"Explained variance with {n_components_95} components: {cumulative_variance[n_components_95-1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2df19d7",
   "metadata": {
    "id": "b2df19d7"
   },
   "source": [
    "### 16. Apply K-means clustering and segment the data (Use PCA transformed data for clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a3a8bb4c",
   "metadata": {
    "id": "a3a8bb4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ID   Education Marital_Status    Income Dt_Customer  Recency  MntWines  \\\n",
      "0  5524  Graduation         Single  0.234063    4/9/2012       58       635   \n",
      "1  2174  Graduation         Single -0.234559    8/3/2014       38        11   \n",
      "2  4141  Graduation   relationship  0.769478  21-08-2013       26       426   \n",
      "3  6182  Graduation   relationship -1.017239   10/2/2014       26        11   \n",
      "4  5324         PhD   relationship  0.240221  19-01-2014       94       173   \n",
      "\n",
      "   MntFruits  MntMeatProducts  MntFishProducts  ...  NumCatalogPurchases  \\\n",
      "0         88              546              172  ...                   10   \n",
      "1          1                6                2  ...                    1   \n",
      "2         49              127              111  ...                    2   \n",
      "3          4               20               10  ...                    0   \n",
      "4         43              118               46  ...                    3   \n",
      "\n",
      "   NumStorePurchases  NumWebVisitsMonth  Complain  Total_Expenses  \\\n",
      "0                  4                  7         0        1.679417   \n",
      "1                  2                  5         0       -0.961275   \n",
      "2                 10                  4         0        0.282673   \n",
      "3                  4                  6         0       -0.918094   \n",
      "4                  6                  5         0       -0.305254   \n",
      "\n",
      "   Num_Total_Purchases  Kids  TotalAcceptedCmp  Age  Cluster  \n",
      "0             1.320826     0                 1   66        1  \n",
      "1            -1.154596     2                 0   69        2  \n",
      "2             0.799685     0                 0   58        1  \n",
      "3            -0.894025     1                 0   39        2  \n",
      "4             0.539114     1                 0   42        0  \n",
      "\n",
      "[5 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "columns_for_pca = ['Income', 'Total_Expenses', 'Num_Total_Purchases']\n",
    "df = df.dropna(subset=columns_for_pca)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=columns_for_pca)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df[columns_for_pca])\n",
    "pca = PCA(n_components=2)  \n",
    "pca_transformed = pca.fit_transform(df_scaled)\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(pca_transformed)\n",
    "cluster_labels = kmeans.labels_\n",
    "df['Cluster'] = cluster_labels\n",
    "print(df.head("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8463aed",
   "metadata": {
    "id": "d8463aed"
   },
   "source": [
    "### 17. Apply Agglomerative clustering and segment the data (Use Original data for clustering), and perform cluster analysis by doing bivariate analysis between the cluster label and different features and write your observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b5ca165b",
   "metadata": {
    "id": "b5ca165b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bivariate analysis between Cluster and Education:\n",
      "   Cluster   Education  Count\n",
      "0        0    2n Cycle     87\n",
      "1        0  Graduation    577\n",
      "2        0      Master    184\n",
      "3        0         PhD    286\n",
      "4        1    2n Cycle    113\n",
      "5        1       Basic     54\n",
      "6        1  Graduation    538\n",
      "7        1      Master    181\n",
      "8        1         PhD    195\n",
      "9        2  Graduation      1\n",
      "\n",
      "Bivariate analysis between Cluster and Marital_Status:\n",
      "    Cluster Marital_Status  Count\n",
      "0         0         Absurd      2\n",
      "1         0          Alone      1\n",
      "2         0       Divorced    123\n",
      "3         0        Married    446\n",
      "4         0         Single    222\n",
      "5         0       Together    292\n",
      "6         0          Widow     48\n",
      "7         1          Alone      2\n",
      "8         1       Divorced    109\n",
      "9         1        Married    411\n",
      "10        1         Single    249\n",
      "11        1       Together    280\n",
      "12        1          Widow     28\n",
      "13        1           YOLO      2\n",
      "14        2       Together      1\n",
      "\n",
      "Bivariate analysis between Cluster and Income:\n",
      "      Cluster    Income  Count\n",
      "0           0   50611.0      2\n",
      "1           0   50664.0      1\n",
      "2           0   50725.0      1\n",
      "3           0   50729.0      1\n",
      "4           0   50737.0      1\n",
      "...       ...       ...    ...\n",
      "1969        1   50501.0      1\n",
      "1970        1   50520.0      1\n",
      "1971        1   50523.0      1\n",
      "1972        1   50616.0      2\n",
      "1973        2  666666.0      1\n",
      "\n",
      "[1974 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and Kidhome:\n",
      "   Cluster  Kidhome  Count\n",
      "0        0        0    958\n",
      "1        0        1    166\n",
      "2        0        2     10\n",
      "3        1        0    325\n",
      "4        1        1    720\n",
      "5        1        2     36\n",
      "6        2        1      1\n",
      "\n",
      "Bivariate analysis between Cluster and Teenhome:\n",
      "   Cluster  Teenhome  Count\n",
      "0        0         0    536\n",
      "1        0         1    569\n",
      "2        0         2     29\n",
      "3        1         0    610\n",
      "4        1         1    449\n",
      "5        1         2     22\n",
      "6        2         0      1\n",
      "\n",
      "Bivariate analysis between Cluster and Recency:\n",
      "     Cluster  Recency  Count\n",
      "0          0        0     15\n",
      "1          0        1     13\n",
      "2          0        2     14\n",
      "3          0        3     18\n",
      "4          0        4     15\n",
      "..       ...      ...    ...\n",
      "196        1       96     11\n",
      "197        1       97     11\n",
      "198        1       98      9\n",
      "199        1       99     10\n",
      "200        2       23      1\n",
      "\n",
      "[201 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntWines:\n",
      "     Cluster  MntWines  Count\n",
      "0          0         1      2\n",
      "1          0         2      1\n",
      "2          0         5      1\n",
      "3          0         6      1\n",
      "4          0         8      2\n",
      "..       ...       ...    ...\n",
      "920        1       777      1\n",
      "921        1       853      1\n",
      "922        1      1039      1\n",
      "923        1      1181      1\n",
      "924        2         9      1\n",
      "\n",
      "[925 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntFruits:\n",
      "     Cluster  MntFruits  Count\n",
      "0          0          0    141\n",
      "1          0          1     19\n",
      "2          0          2     13\n",
      "3          0          3     12\n",
      "4          0          4     20\n",
      "..       ...        ...    ...\n",
      "214        1        104      1\n",
      "215        1        122      1\n",
      "216        1        133      1\n",
      "217        1        151      1\n",
      "218        2         14      1\n",
      "\n",
      "[219 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntMeatProducts:\n",
      "     Cluster  MntMeatProducts  Count\n",
      "0          0                1      1\n",
      "1          0                2      1\n",
      "2          0                3      3\n",
      "3          0                4      3\n",
      "4          0                5      2\n",
      "..       ...              ...    ...\n",
      "681        1              243      1\n",
      "682        1              248      1\n",
      "683        1              267      2\n",
      "684        1             1725      1\n",
      "685        2               18      1\n",
      "\n",
      "[686 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntFishProducts:\n",
      "     Cluster  MntFishProducts  Count\n",
      "0          0                0    131\n",
      "1          0                1      4\n",
      "2          0                2     18\n",
      "3          0                3     14\n",
      "4          0                4     16\n",
      "..       ...              ...    ...\n",
      "249        1              175      1\n",
      "250        1              179      1\n",
      "251        1              197      1\n",
      "252        1              208      1\n",
      "253        2                8      1\n",
      "\n",
      "[254 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntSweetProducts:\n",
      "     Cluster  MntSweetProducts  Count\n",
      "0          0                 0    156\n",
      "1          0                 1     15\n",
      "2          0                 2     13\n",
      "3          0                 3     14\n",
      "4          0                 4     15\n",
      "..       ...               ...    ...\n",
      "231        1               112      1\n",
      "232        1               129      1\n",
      "233        1               151      1\n",
      "234        1               157      1\n",
      "235        2                 1      1\n",
      "\n",
      "[236 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and MntGoldProds:\n",
      "     Cluster  MntGoldProds  Count\n",
      "0          0             0     30\n",
      "1          0             1      8\n",
      "2          0             2      7\n",
      "3          0             3      3\n",
      "4          0             4     13\n",
      "..       ...           ...    ...\n",
      "315        1           219      1\n",
      "316        1           262      1\n",
      "317        1           291      1\n",
      "318        1           321      1\n",
      "319        2            12      1\n",
      "\n",
      "[320 rows x 3 columns]\n",
      "\n",
      "Bivariate analysis between Cluster and NumWebVisitsMonth:\n",
      "    Cluster  NumWebVisitsMonth  Count\n",
      "0         0                  0      9\n",
      "1         0                  1    148\n",
      "2         0                  2    188\n",
      "3         0                  3    169\n",
      "4         0                  4    157\n",
      "5         0                  5    147\n",
      "6         0                  6    139\n",
      "7         0                  7     96\n",
      "8         0                  8     73\n",
      "9         0                  9      8\n",
      "10        1                  0      1\n",
      "11        1                  1      2\n",
      "12        1                  2     13\n",
      "13        1                  3     34\n",
      "14        1                  4     60\n",
      "15        1                  5    132\n",
      "16        1                  6    195\n",
      "17        1                  7    291\n",
      "18        1                  8    267\n",
      "19        1                  9     74\n",
      "20        1                 10      3\n",
      "21        1                 13      1\n",
      "22        1                 14      2\n",
      "23        1                 17      1\n",
      "24        1                 19      2\n",
      "25        1                 20      3\n",
      "26        2                  6      1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('marketing.csv')\n",
    "columns_for_clustering = ['Income', 'Kidhome', 'Teenhome', 'Recency', 'MntWines', 'MntFruits',\n",
    "                          'MntMeatProducts', 'MntFishProducts', 'MntSweetProducts', 'MntGoldProds',\n",
    "                          'NumWebVisitsMonth']\n",
    "df = df.dropna(subset=columns_for_clustering)\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=columns_for_clustering)\n",
    "agglomerative = AgglomerativeClustering(n_clusters=3)  \n",
    "cluster_labels = agglomerative.fit_predict(df[columns_for_clustering])\n",
    "df['Cluster'] = cluster_labels\n",
    "cluster_features = ['Education', 'Marital_Status', 'Income', 'Kidhome', 'Teenhome', 'Recency',\n",
    "                    'MntWines', 'MntFruits', 'MntMeatProducts', 'MntFishProducts',\n",
    "                    'MntSweetProducts', 'MntGoldProds', 'NumWebVisitsMonth']\n",
    "for feature in cluster_features:\n",
    "    analysis = df.groupby(['Cluster', feature]).size().reset_index(name='Count')\n",
    "    print(f\"Bivariate analysis between Cluster and {feature}:\")\n",
    "    print(analysis)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797a5ecd",
   "metadata": {
    "id": "797a5ecd"
   },
   "source": [
    "### Visualization and Interpretation of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e75760",
   "metadata": {
    "id": "d1e75760"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "36afd95b",
   "metadata": {
    "id": "36afd95b"
   },
   "source": [
    "-----\n",
    "## Happy Learning\n",
    "-----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "36afd95b"
   ],
   "name": "Unsupervised Learning - Lab session.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
